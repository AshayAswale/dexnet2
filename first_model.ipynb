{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/jibran/dexnet_ws/gqcnn/data/training/dex-net_2.0/tensors\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "DATA = os.getenv('DEXNET_DATA')\n",
    "print(DATA)                     #Confirm if path is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['table_mask', 'depth_ims_raw', 'image_labels', 'hand_poses', 'depth_ims_tf_table', 'robust_ferrari_canny', 'binary_ims_tf', 'binary_ims_raw', 'force_closure', 'object_labels', 'depth_ims_raw_table', 'pose_labels', 'depth_ims_tf'])\n"
     ]
    }
   ],
   "source": [
    "arrays = {}\n",
    "datapoint = '_05590.npz'                #Enter datapoint here (anywhere between _00000 and _06728, there are a total of 6.7 million datapoints)\n",
    "for filename in os.listdir(DATA):\n",
    "    if filename.endswith(datapoint):\n",
    "        arrays[filename.replace(datapoint, '')] = np.load('/home/jibran/dexnet_ws/gqcnn/data/training/dex-net_2.0/tensors/'+filename)\n",
    "\n",
    "features = {}\n",
    "for array in arrays:\n",
    "    f = arrays[array]\n",
    "    feature = f['arr_0.npy']\n",
    "    features[array] = feature\n",
    "print(features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1000,)\n(1000,)\n(1000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "#Inputs to feed into CNN\n",
    "aligned_imgs = features['depth_ims_tf_table']\n",
    "# print(aligned_imgs.shape)\n",
    "gripper_depths = features['hand_poses'][:, 2]          #aligned_imgs and gripper_depths are the X of our model (Refer to gqcnn/Data.README.md)\n",
    "# print(gripper_depths.shape)\n",
    "grasp_metrics = features['robust_ferrari_canny']       #Y of our model (Grasp metric)\n",
    "\n",
    "#Verify shapes \n",
    "\n",
    "print(grasp_metrics.shape)\n",
    "print(gripper_depths.shape)\n",
    "print(aligned_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "# example of defining the discriminator model\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Lambda\n",
    "from tensorflow.nn import local_response_normalization\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "# from tensorflow.keras import layers\n",
    "from keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'dense')>,\n",
       " <KerasTensor: shape=(None, 32, 32, 1) dtype=float32 (created by layer 'img')>)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "def getGraspQualityVariable():\n",
    "    input = Input(shape=(32, 32, 1), name=\"img\")\n",
    "    x1 = Conv2D(filters=64, kernel_size=7, activation='relu')(input)\n",
    "    x2 = Conv2D(filters=64, kernel_size=5, activation='relu')(x1)\n",
    "    x3 = Lambda(local_response_normalization)(x2)\n",
    "    x4 = MaxPooling2D(pool_size=(2, 2), strides=2)(x3)\n",
    "    x5 = Conv2D(filters=64, kernel_size=3, activation='relu')(x4)\n",
    "    x6 = Conv2D(filters=64, kernel_size=3, activation='relu')(x5)\n",
    "    x7 = Lambda(local_response_normalization)(x6)\n",
    "    x8 = Flatten()(x7)\n",
    "    x9 = Dense(1024, activation='relu')(x8)\n",
    "    \n",
    "    # plot_model(model, to_file='GraspQualityModel_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    return x9, input\n",
    "    \n",
    "getGraspQualityVariable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPointcloudModel():\n",
    "    input = Input(shape=(1), name=\"z\")\n",
    "    x = Dense(16, input_dim=1, activation='relu')(input)\n",
    "    return x, input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import concatenate\n",
    "def getDexnet2Model():\n",
    "    grasp_model, input_1 = getGraspQualityVariable()\n",
    "    pc_model, input_2 = getPointcloudModel()\n",
    "\n",
    "    out = Dense(1024, activation='relu')\n",
    "\n",
    "    # x = layers.concatenate([grasp_model, pc_model])\n",
    "    merge = concatenate([grasp_model, pc_model])\n",
    "    out_1 = Dense(1024, activation='relu')(merge)\n",
    "    out_2 = Dense(2, activation='softmax')(out_1)\n",
    "    model = Model(inputs=[input_1, input_2], outputs=out_2)\n",
    "    plot_model(model, to_file='Dexnet2_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    return model\n",
    "\n",
    "first_model = getDexnet2Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nimg (InputLayer)                [(None, 32, 32, 1)]  0                                            \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 26, 26, 64)   3200        img[0][0]                        \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 22, 22, 64)   102464      conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nlambda_6 (Lambda)               (None, 22, 22, 64)   0           conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 11, 11, 64)   0           lambda_6[0][0]                   \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 9, 9, 64)     36928       max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 7, 7, 64)     36928       conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nlambda_7 (Lambda)               (None, 7, 7, 64)     0           conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nflatten_3 (Flatten)             (None, 3136)         0           lambda_7[0][0]                   \n__________________________________________________________________________________________________\nz (InputLayer)                  [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ndense_11 (Dense)                (None, 1024)         3212288     flatten_3[0][0]                  \n__________________________________________________________________________________________________\ndense_12 (Dense)                (None, 16)           32          z[0][0]                          \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 1040)         0           dense_11[0][0]                   \n                                                                 dense_12[0][0]                   \n__________________________________________________________________________________________________\ndense_14 (Dense)                (None, 1024)         1065984     concatenate_2[0][0]              \n__________________________________________________________________________________________________\ndense_15 (Dense)                (None, 2)            2050        dense_14[0][0]                   \n==================================================================================================\nTotal params: 4,459,874\nTrainable params: 4,459,874\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "first_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'x_valid' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3a6fa43e1cc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m           callbacks=[checkpointer])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_valid' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights/first_model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "x_train = [aligned_imgs, gripper_depths]\n",
    "y_train = grasp_metrics\n",
    "first_model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=32,\n",
    "          epochs=1, \n",
    "          validation_split=0.2,\n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}